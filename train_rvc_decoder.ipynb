{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将通过RVC换声后的音频数据用来训练Decoder解码器以实现音色固定的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function with hidden transposed and shapes maintained throughout.\n",
    "    \n",
    "    Args:\n",
    "        batch (List[Tuple[Tensor, Tensor]]): List of tuples, each containing a pair of hidden and log_mel_spec tensors.\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Tensor]: A dictionary with keys 'hidden' and 'log_mel_spec', \n",
    "        each associated with a padded tensor, with 'hidden' remaining in its transposed shape.\n",
    "    \"\"\"\n",
    "    # Separate inputs and transpose hidden\n",
    "    hidden_list_transposed, log_mel_spec_list = zip(*[(h.transpose(0, 1), l) for h, l in batch])\n",
    "    \n",
    "    # Calculate the maximum lengths based on the transposed shapes\n",
    "    max_len_hidden = max([h.size(1) for h in hidden_list_transposed])  # Now looking at the first dimension after transpose\n",
    "    max_len_log_mel_spec = max_len_hidden * 2\n",
    "    \n",
    "    # Pad hidden and log_mel_spec sequences\n",
    "    hidden_padded = torch.stack([pad(h, (0, max_len_hidden - h.size(1)), value=0) for h in hidden_list_transposed])\n",
    "    log_mel_spec_padded = torch.stack([pad(l, (0, max_len_log_mel_spec - l.size(1)), value=0) for l in log_mel_spec_list])\n",
    "    \n",
    "    # Generate masks for log_mel_spec sequences\n",
    "    log_mel_spec_masks = []\n",
    "    for l in log_mel_spec_list:\n",
    "        mask = torch.ones(l.size(0), l.size(1), dtype=torch.bool)\n",
    "        mask = pad(mask, (0, max_len_log_mel_spec - l.size(1)), value=0)\n",
    "        log_mel_spec_masks.append(mask)\n",
    "    log_mel_spec_masks = torch.stack(log_mel_spec_masks)\n",
    "\n",
    "    # Return a dictionary with padded tensors, hidden remains in its transposed state\n",
    "    return {\n",
    "        'hidden': hidden_padded,  # Already in the desired transposed shape\n",
    "        'log_mel_spec': log_mel_spec_padded,\n",
    "        'log_mel_spec_mask': log_mel_spec_masks,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import glob\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    \n",
    "if 'mps' in str(device):\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] ='1'\n",
    "    # 在jupyter notebook 里面还需要额外引入一个魔法命令\n",
    "    try:\n",
    "        # 只在jupyter notebook中运行\n",
    "        from IPython import get_ipython\n",
    "        if get_ipython() is not None:\n",
    "            %set_env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "class MelSpecDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        super(MelSpecDataset, self).__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.npz_files = glob.glob(f\"{data_dir}/*.npz\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.npz_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        npz_file = self.npz_files[idx]\n",
    "        data = np.load(npz_file)\n",
    "        \n",
    "        # 获取输入特征和目标特征\n",
    "        hidden = data[\"hidden\"]\n",
    "        log_mel_spec = data[\"log_mel_spec\"]\n",
    "        \n",
    "        # 将 NumPy 数组转换为 PyTorch 张量\n",
    "        hidden = torch.from_numpy(hidden).float()\n",
    "        log_mel_spec = torch.from_numpy(log_mel_spec).float()\n",
    "        \n",
    "        # 返回输入和目标张量\n",
    "        return hidden, log_mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.dvae import GradualDVAEDecoder,ImprovedGradualDVAEDecoder\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from modules.discriminator import DynamicAudioDiscriminatorWithResidual\n",
    "\n",
    "class LightningGradualDVAEDecoder(pl.LightningModule):\n",
    "    def __init__(self, idim, odim, n_layer=12, bn_dim=64, hidden=256, kernel=3, dilation=2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()  # 这一行会自动保存模型的参数为超参数\n",
    "        self.model = ImprovedGradualDVAEDecoder(\n",
    "            idim, odim, n_layer, bn_dim, hidden, kernel, dilation)\n",
    "        self.loss_fn = MSELoss()  # 假设我们使用均方误差作为损失函数\n",
    "        self.l1_loss_fn = L1Loss()  # 使用 L1 损失作为辅助损失函数\n",
    "\n",
    "    def preprocess(self,vq_feats:torch.Tensor) -> torch.Tensor:\n",
    "        # 通过调整量化特征的维度来准备解码\n",
    "        # 将特征沿着 dim=1 维度分成两部分，得到两个形状为 (1, 512, 121) 的张量。\n",
    "        temp = torch.chunk(vq_feats, 2, dim=1)  # flatten trick :)\n",
    "        # 将这两个张量堆叠在一起，得到形状为 (1, 512, 121, 2) 的张量\n",
    "        temp = torch.stack(temp, -1)\n",
    "        # 重新调整特征形状，得到 vq_feats 形状为 (1, 512, 242)\n",
    "        vq_feats = temp.reshape(*temp.shape[:2], -1)\n",
    "\n",
    "        return vq_feats\n",
    "    def forward(self, vq_feats):\n",
    "        vq_feats = self.preprocess(vq_feats)\n",
    "        return self.model(vq_feats)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # 注意：这里直接使用collate_fn处理后的数据结构\n",
    "        hidden, target = batch['hidden'], batch['log_mel_spec']\n",
    "        target_mask = batch['log_mel_spec_mask']\n",
    "\n",
    "        output = self(hidden)\n",
    "\n",
    "        # Apply mask to output to zero out padded parts\n",
    "        output_masked = output * target_mask.float()\n",
    "\n",
    "        loss = self.loss_fn(output_masked, target)\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        hidden, target = batch['hidden'], batch['log_mel_spec']\n",
    "        target_mask = batch['log_mel_spec_mask']\n",
    "        \n",
    "        output = self(hidden)\n",
    "\n",
    "        # Apply mask to output to zero out padded parts\n",
    "        output_masked = output * target_mask.float()\n",
    "        \n",
    "        # 计算 MSE 损失\n",
    "        mse_loss = self.loss_fn(output_masked, target)\n",
    "        self.log('val_mse_loss', mse_loss, prog_bar=True, logger=True)\n",
    "\n",
    "        # 计算 L1 损失\n",
    "        l1_loss = self.l1_loss_fn(output_masked, target)\n",
    "        self.log('val_l1_loss', l1_loss, prog_bar=True, logger=True)\n",
    "\n",
    "        # 返回一个字典，包含所有记录的损失值\n",
    "        return {'val_mse_loss': mse_loss, 'val_l1_loss': l1_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=1e-3)  # 你可以根据需求调整学习率和其他参数\n",
    "        # 余弦退火\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=128, T_mult=2, eta_min=1e-6)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Faster, but less precise\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# 使用自定义的 Dataset 类\n",
    "dataset = MelSpecDataset(\"./train_rvc\")\n",
    "\n",
    "# Accessing a sample\n",
    "sample_hidden, sample_mel_spec = dataset[0]\n",
    "print(f\"Sample hidden shape: {sample_hidden.shape}\")\n",
    "print(f\"Sample mel spec shape: {sample_mel_spec.shape}\")\n",
    "\n",
    "# 设定训练集和验证集的比例\n",
    "train_val_ratio = 0.90\n",
    "val_size = int(len(dataset) * (1 - train_val_ratio))\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "# 使用 random_split 分割数据集\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "if 'cuda' in str(device):\n",
    "    batch_size = 40\n",
    "else:\n",
    "    batch_size = 1\n",
    "\n",
    "# 创建 DataLoader 以批量加载数据\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# 打印数量\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "\n",
    "# 实例化你的 Lightning 模型\n",
    "IDIM = 384\n",
    "ODIM = 100\n",
    "model_params = {\n",
    "    'idim':IDIM, \n",
    "    'odim':ODIM, \n",
    "    'bn_dim':256,\n",
    "    'hidden':512,\n",
    "    'n_layer':2,\n",
    "}\n",
    "model = LightningGradualDVAEDecoder(**model_params)\n",
    "\n",
    "# 自定义检查点保存的目录\n",
    "checkpoint_dir = './checkpoints'\n",
    "latest_checkpoint = sorted(glob.glob(os.path.join(\n",
    "    checkpoint_dir, '*.ckpt')), key=os.path.getmtime, reverse=True)\n",
    "\n",
    "# 检查是否有可用的检查点文件\n",
    "if latest_checkpoint:\n",
    "    last_checkpoint_path = latest_checkpoint[0]\n",
    "    print(\n",
    "        f\"Resuming training from the latest checkpoint: {last_checkpoint_path}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n",
    "    last_checkpoint_path = None\n",
    "\n",
    "\n",
    "# 添加 ModelCheckpoint 回调，设置保存条件和频率\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='step',  # 监控的指标，用于决定是否保存模型\n",
    "    mode='max',          # 监控指标的模式，这里是最小化验证损失\n",
    "    save_top_k=10,       # 保持最新的 10 个模型文件\n",
    "    # every_n_epochs=1,    # 每个 epoch 保存一次模型\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # 模型文件名的格式\n",
    "    auto_insert_metric_name=False,  # 不自动在文件名中插入监控的指标名,\n",
    "    every_n_train_steps=2000,  # save checkpoints every 2000 steps\n",
    "    dirpath=checkpoint_dir,\n",
    ")\n",
    "\n",
    "# 添加 EarlyStopping 回调，设置早停条件\n",
    "early_stop_callback = pl.callbacks.EarlyStopping(\n",
    "    monitor='val_mse_loss',\n",
    "    min_delta=0.1,  # 最小变化量，小于这个值的变化不会触发早停\n",
    "    patience=10,       # 在满足条件后，继续训练的 epoch 数\n",
    "    verbose=True,      # 是否在控制台输出早停信息\n",
    "    mode='min'         # 监控指标的模式，这里是最小化验证损失\n",
    ")\n",
    "\n",
    "# 设置TensorBoard日志存储的根目录\n",
    "tb_logger = TensorBoardLogger(save_dir=\"./tensorboard/\",log_graph=False,default_hp_metric=True,name=None,version=None)\n",
    "\n",
    "# 初始化 PyTorch Lightning Trainer\n",
    "max_epochs = 1000\n",
    "callbacks = [checkpoint_callback] # 忽略早停法\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, \n",
    "                     accelerator=\"auto\", \n",
    "                     devices=\"auto\",\n",
    "                     # callbacks=[checkpoint_callback, early_stop_callback],\n",
    "                     callbacks=callbacks,\n",
    "                        precision=\"16-mixed\",  # 这一行开启了混合精度训练\n",
    "                     logger=tb_logger,  # 这里指定了TensorBoard日志记录器\n",
    "                    )\n",
    "\n",
    "# 正式开始训练之前打印参数\n",
    "print(f\"model_params: {model_params}\")\n",
    "\n",
    "# 开始训练\n",
    "last_checkpoint_path = None # 暂时不从检查点恢复\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader,ckpt_path = last_checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
